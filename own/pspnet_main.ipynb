{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, 68, 120, 1024), dtype=float32, sparse=False, name=keras_tensor_2915> features\n",
      "<KerasTensor shape=(None, 68, 120, 2048), dtype=float32, sparse=False, name=keras_tensor_2916> ppm\n",
      "<KerasTensor shape=(None, 68, 120, 512), dtype=float32, sparse=False, name=keras_tensor_2919> after conv\n",
      "<KerasTensor shape=(None, 1088, 1920, 512), dtype=float32, sparse=False, name=keras_tensor_2920> cus upsam\n",
      "<KerasTensor shape=(None, 1080, 1920, 40), dtype=float32, sparse=False, name=keras_tensor_2922> logits\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def build_backbone(input_shape):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,  # We only need the starting blocks not the outputs\n",
    "        weights='imagenet')\n",
    "    output = base_model.get_layer('conv4_block6_out').output\n",
    "    return Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Pyramid Pooling Module (PPM)\n",
    "from keras import backend as K\n",
    "\n",
    "# def pyramid_pooling_module(input_tensor, pool_sizes):\n",
    "#     input_shape = K.int_shape(input_tensor)[1:3]  # (H, W)\n",
    "#     pooled_outputs = [input_tensor]\n",
    "\n",
    "#     for pool_size in pool_sizes:\n",
    "#         pooled = layers.AveragePooling2D(pool_size)(input_tensor)\n",
    "#         pooled = layers.Conv2D(512, (1, 1), use_bias=False)(pooled)\n",
    "#         pooled = layers.BatchNormalization()(pooled)\n",
    "#         pooled = layers.ReLU()(pooled)\n",
    "#         pooled = layers.Lambda(lambda x: tf.image.resize(x, input_shape))(pooled)\n",
    "#         pooled_outputs.append(pooled)\n",
    "\n",
    "#     return layers.Concatenate()(pooled_outputs)\n",
    "\n",
    "class CusResize(layers.Layer):\n",
    "    def __init__(self, input_size, method=\"bilinear\"):\n",
    "        super(CusResize, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.method = method\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.image.resize(x, self.input_size, method =self.method)\n",
    "\n",
    "\n",
    "class PyramidPoolingLayer(layers.Layer):\n",
    "    def __init__(self, pool_sizes):\n",
    "        super(PyramidPoolingLayer, self).__init__()\n",
    "        self.pool_sizes = pool_sizes\n",
    "\n",
    "    def call(self, x):\n",
    "        input_height, input_width = tf.shape(x)[1], tf.shape(x)[2]\n",
    "        pool_outputs = []\n",
    "        for pool_size in self.pool_sizes:\n",
    "            pooled = layers.AveragePooling2D(pool_size)(x)\n",
    "            pooled = layers.Conv2D(512, (1, 1), padding='same')(pooled)\n",
    "            upsam = layers.UpSampling2D(size=pool_size, interpolation='bilinear')(pooled)\n",
    "            resized = CusResize([input_height, input_width], method='bilinear')(upsam)\n",
    "            pool_outputs.append(resized)\n",
    "        return layers.Concatenate()(pool_outputs)\n",
    "\n",
    "\n",
    "# PSPNet model\n",
    "def build_pspnet(input_shape=(1080, 1920, 3), num_classes=40):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Backbone feature extraction (ResNet)\n",
    "    backbone = build_backbone(input_shape)\n",
    "    features = backbone(inputs)\n",
    "    # print(features, \"features\")\n",
    "    \n",
    "    ppm = PyramidPoolingLayer(pool_sizes=[(1, 1), (2, 2), (4, 4), (8, 8)])(features)\n",
    "    # print(ppm, \"ppm\")\n",
    "\n",
    "    x = layers.Conv2D(512, (3, 3), padding=\"same\", use_bias=False)(ppm)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    # print(x, \"after conv\")\n",
    "    \n",
    "    x = layers.Concatenate()([x, features])\n",
    "    x = layers.Conv2D(512, (3, 3), padding=\"same\")(x)\n",
    "\n",
    "    # Upsample to input image size\n",
    "    x = layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(x)\n",
    "    # print(x, \"cus upsam\")\n",
    "    \n",
    "    x = CusResize(input_shape[:2])(x)  \n",
    "    # x = layers.Concatenate()([x, inputs])\n",
    "\n",
    "    x = layers.Conv2D(num_classes, (1, 1))(x)\n",
    "    outputs = layers.Softmax()(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "input_shape = (1080, 1920, 3) \n",
    "num_classes = 40  \n",
    "pspnet_model = build_pspnet(input_shape, num_classes)\n",
    "\n",
    "pspnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset from the provided text file.\n",
      "C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame0029_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame0029_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame0299_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame0299_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame0779_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame0779_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame2519_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame2519_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame2819_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame2819_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame3179_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame3179_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame3749_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame3749_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\201\\frame4079_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\201\\frame4079_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\202\\frame0018_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\202\\frame0018_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\202\\frame0389_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\202\\frame0389_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\203\\frame0165_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\203\\frame0165_gtFine_labelColors.png\n",
      " Load dataset from the provided text file.\n",
      "C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\213\\frame29505_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\213\\frame29505_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\478\\frame3074_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\478\\frame3074_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\209\\frame0689_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\209\\frame0689_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\441\\frame1274_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\441\\frame1274_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\548\\0014136_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\548\\0014136_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\263\\frame67349_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\263\\frame67349_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\320\\frame13986_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\320\\frame13986_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\203\\frame1777_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\203\\frame1777_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\460\\frame88484_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\460\\frame88484_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\213\\frame42249_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\213\\frame42249_gtFine_labelColors.png\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/train\\302\\frame6128_leftImg8bit.jpg C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/labels\\302\\frame6128_gtFine_labelColors.png\n",
      " Load dataset from the provided text file.\n",
      "C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0000_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0014_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0119_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0199_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0277_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0340_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0342_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0364_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0514_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0550_leftImg8bit.jpg\n",
      " C:/Users/hp/Documents/code/Py/actual/Ai/inter_boot_2024/own/dataset/test\\frame0604_leftImg8bit.jpg\n",
      " "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "CLASS_COLORS = [\n",
    "    [128, 64, 128], [250, 170, 160], [81, 0, 81], [244, 35, 232], [230, 150, 140],\n",
    "    [152, 251, 152], [220, 20, 60], [246, 198, 145], [255, 0, 0], [0, 0, 230],\n",
    "    [119, 11, 32], [255, 204, 54], [0, 0, 142], [0, 0, 70], [0, 60, 100],\n",
    "    [0, 0, 90], [0, 0, 110], [0, 80, 100], [136, 143, 153], [220, 190, 40],\n",
    "    [102, 102, 156], [190, 153, 153], [180, 165, 180], [174, 64, 67], [220, 220, 0],\n",
    "    [250, 170, 30], [153, 153, 153], [153, 153, 153], [169, 187, 214], [70, 70, 70],\n",
    "    [150, 100, 100], [150, 120, 90], [107, 142, 35], [70, 130, 180], [169, 187, 21],\n",
    "    [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 142]\n",
    "]\n",
    "\n",
    "def rgb_to_class_tensor(rgb_mask):\n",
    "    if rgb_mask.shape[-1] == 4: # alpha handling\n",
    "        rgb_mask = rgb_mask[..., :3]\n",
    "\n",
    "    height, width, _ = rgb_mask.shape\n",
    "    class_tensor = np.zeros((height, width, len(CLASS_COLORS)), dtype=np.float32)\n",
    "\n",
    "    for i, color in enumerate(CLASS_COLORS):\n",
    "        mask = np.all(rgb_mask == color, axis=-1) \n",
    "        class_tensor[mask, i] = 1 \n",
    "\n",
    "    return class_tensor\n",
    "\n",
    "def class_tensor_to_rgb(class_tensor):\n",
    "    height, width, num_classes = class_tensor.shape\n",
    "    rgb_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    class_indices = np.argmax(class_tensor, axis=-1)\n",
    "    \n",
    "    for i, color in enumerate(CLASS_COLORS):\n",
    "        rgb_mask[class_indices == i] = color\n",
    "    \n",
    "    return rgb_mask\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    print(\"\"\"Load dataset from the provided text file.\"\"\")\n",
    "    input_images = []\n",
    "    masks = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        # test = 0\n",
    "        for line in f:\n",
    "            \n",
    "            # if test > 10:\n",
    "            #     break\n",
    "            # test += 1\n",
    "\n",
    "            print(line, end=\" \")\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2: \n",
    "                image_path, mask_path = parts\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (1920, 1080))\n",
    "                input_images.append(image)\n",
    "                \n",
    "                mask = cv2.imread(mask_path)\n",
    "                mask = cv2.resize(mask, (1920, 1080))\n",
    "                class_tensor = rgb_to_class_tensor(mask)\n",
    "                masks.append(class_tensor)\n",
    "\n",
    "            elif len(parts) == 1: \n",
    "                image_path = parts[0]\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (1920, 1080))\n",
    "                input_images.append(image)\n",
    "                masks.append(None)\n",
    "\n",
    "    return np.array(input_images), np.array(masks)\n",
    "\n",
    "\n",
    "train_images, train_masks = load_dataset('data/training.txt')\n",
    "val_images, val_masks = load_dataset('data/validation.txt')\n",
    "test_images, _ = load_dataset('data/testing.txt')\n",
    "\n",
    "\n",
    "def create_dataset(images, masks, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=len(images))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def augment_image(img, mask):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    return img, mask\n",
    "\n",
    "batch_size = 32 \n",
    "train_dataset = create_dataset(train_images, train_masks, batch_size)\n",
    "train_dataset.map(augment_image)\n",
    "val_dataset = create_dataset(val_images, val_masks, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")]\n",
    "\n",
    "pspnet_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = pspnet_model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=epochs\n",
    "    )\n",
    "pspnet_model.save(\"psp.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(model, test_images, output_folder=\"model_output\"):\n",
    "    import os\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    predictions = model.predict(test_images)\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "        rgb_mask = class_tensor_to_rgb(pred)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f\"predicted_mask_{i}.png\")\n",
    "        cv2.imwrite(output_path, rgb_mask)\n",
    "\n",
    "predict_and_save(pspnet_model, test_images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
